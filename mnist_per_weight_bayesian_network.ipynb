{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef56gCUqrdVn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import random; random.seed(42)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "assert tf.executing_eagerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E14tL1vUuTRV"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXNp_25y7JP2"
   },
   "source": [
    "DP-SGD has three privacy-specific hyperparameters and one existing hyperamater that you must tune:\n",
    "\n",
    "1. `l2_norm_clip` (float) - The maximum Euclidean (L2) norm of each gradient that is applied to update model parameters. This hyperparameter is used to bound the optimizer's sensitivity to individual training points. \n",
    "2. `noise_multiplier` (float) - The amount of noise sampled and added to gradients during training. Generally, more noise results in better privacy (often, but not necessarily, at the expense of lower utility).\n",
    "3.   `microbatches` (int) - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVw_r2Mq7ntd"
   },
   "outputs": [],
   "source": [
    "l2_norm_clip = 0.5\n",
    "noise_multiplier = 1\n",
    "gaussian_stdev = l2_norm_clip * noise_multiplier\n",
    "gaussian_noise_var = gaussian_stdev ** 2\n",
    "public_var_multiplier = 1 # Multiply public variance by this multiplier\n",
    "public_stdev_multipler = math.sqrt(public_var_multiplier)\n",
    "num_microbatches = batch_size\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "  raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1ML23FlueTr"
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "train_data = np.expand_dims(train_data, len(train_data.shape))\n",
    "test_data = np.expand_dims(test_data, len(test_data.shape))\n",
    "\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "assert train_data.min() == 0.\n",
    "assert train_data.max() == 1.\n",
    "assert test_data.min() == 0.\n",
    "assert test_data.max() == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size refers to private data size\n",
    "public_data, private_data, public_labels, private_labels = \\\n",
    "    train_test_split(train_data, train_labels, test_size=199/200)\n",
    "\n",
    "num_batches = private_data.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28, 1)\n",
      "(300, 10)\n",
      "(59700, 28, 28, 1)\n",
      "(59700, 10)\n"
     ]
    }
   ],
   "source": [
    "print(public_data.shape)\n",
    "print(public_labels.shape)\n",
    "print(private_data.shape)\n",
    "print(private_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws8-nVuVDgtJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.168% and noise_multiplier = 1 iterated over 597 steps satisfies differential privacy with eps = 1.07 and delta = 1e-05.\n",
      "The optimal RDP order is 12.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0661600902513837, 12.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    n=private_labels.shape[0], batch_size=batch_size, noise_multiplier=noise_multiplier, epochs=epochs, delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqBvjCf5-ZXy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                50        \n",
      "=================================================================\n",
      "Total params: 3,190\n",
      "Trainable params: 3,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# ~3k parameters, ~80% accuracy\n",
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.load_weights('mnist_tiny_initial_weights.h5')\n",
    "    return model\n",
    "\n",
    "print(cnn_model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def construct_graphical_model_and_get_map(public_grads, dp_grads):\n",
    "    num_parameters_by_layer = [l.shape[0] for l in dp_grads]\n",
    "    weights_and_biases_by_layer = list(chunks(num_parameters_by_layer, 2))\n",
    "    public_weights_and_biases_by_layer = list(chunks(num_parameters_by_layer, 2))\n",
    "    weights_by_layer = [params[0] for params in weights_and_biases_by_layer]\n",
    "    weights_beginning_index_by_layer = np.append([0], weights_by_layer[:-1])\n",
    "    \n",
    "    map_grads = [np.zeros_like(l) for l in dp_grads]\n",
    "    grad_name_mapping = {}\n",
    "    \n",
    "    graphical_model = pm.Model()\n",
    "    bias_idx = 0\n",
    "    weight_idx = 0\n",
    "    \n",
    "    for layer_num, layer in enumerate(tqdm(dp_grads, desc='Graph Layer', leave=False)):\n",
    "        it = np.nditer(layer, flags=['multi_index'])\n",
    "        \n",
    "        for _ in tqdm(it, desc='Graph Weight', leave=False, total=dp_grads[layer_num].size):\n",
    "            public_grads_layer = public_grads[layer_num][(slice(None), *it.multi_index)]\n",
    "            public_grads_mean = np.mean(public_grads_layer)\n",
    "            public_grads_stdev = np.std(public_grads_layer, ddof=1) * public_stdev_multipler\n",
    "            public_grads_var = public_grads_stdev ** 2\n",
    "            dp_grad = it[0]\n",
    "            \n",
    "            # MAP for two Gaussians is\n",
    "            # ((variance * observed) + (gaussian_noise_var * mean)) / (variances + gaussian_noise_var)\n",
    "            if layer_num % 2 == 1: # Bias\n",
    "                map_estimate = ((public_grads_var * dp_grad) + (public_grads_mean * gaussian_noise_var)) \\\n",
    "                                / (public_grads_var + gaussian_noise_var)\n",
    "                map_grads[layer_num][it.multi_index] = map_estimate\n",
    "                grad_name_mapping[f\"bias_{bias_idx}\"] = (layer_num, it.multi_index)\n",
    "                with graphical_model:\n",
    "                    exec(f\"bias_{bias_idx} = pm.Normal('bias_{bias_idx}', \\\n",
    "                            mu=public_grads_mean, sigma=public_grads_stdev)\")\n",
    "                    exec(f\"bias_observed_{bias_idx} = pm.Normal('bias_observed_{bias_idx}', \\\n",
    "                             mu=weight_{bias_idx}, sigma=gaussian_stdev, observed=dp_grad)\")\n",
    "                bias_idx += 1\n",
    "                \n",
    "            else:  # Weight\n",
    "                weight_layer_num = layer_num // 2\n",
    "                grad_name_mapping[f\"weight_{weight_idx}\"] = (layer_num, it.multi_index)\n",
    "                if weight_layer_num == 0:\n",
    "                    with graphical_model:\n",
    "                        exec(f\"weight_{weight_idx} = pm.Normal('weight_{weight_idx}', \\\n",
    "                                mu=public_grads_mean, sigma=public_grads_stdev)\")\n",
    "                        exec(f\"weight_observed_{weight_idx} = pm.Normal('weight_observed_{weight_idx}', \\\n",
    "                                 mu=weight_{weight_idx}, sigma=gaussian_stdev, observed=dp_grad)\")\n",
    "                else:\n",
    "                    neuron_idx = it.multi_index[0]\n",
    "                    upstream_weights = public_grads[layer_num-2][:, :, neuron_idx]\n",
    "                    num_upstream_weights = upstream_weights.shape[1]\n",
    "                    coeffs = np.linalg.lstsq(upstream_weights, public_grads_layer, rcond=None)[0]\n",
    "                    \n",
    "                    upstream_weight_starting_index = weights_beginning_index_by_layer[weight_layer_num-1] \\\n",
    "                                                        + neuron_idx * num_upstream_weights\n",
    "                    upstream_weight_ending_index = upstream_weight_starting_index + num_upstream_weights\n",
    "                    upstream_weight_indices = range(upstream_weight_starting_index,\n",
    "                                                    upstream_weight_ending_index)\n",
    "                    upstream_weight_coeff_strings = [f'{coeff} * weight_{idx}' \n",
    "                                                         for (coeff, idx) in zip(coeffs, upstream_weight_indices)]\n",
    "                    combined_string = ' + '.join(upstream_weight_coeff_strings)\n",
    "                    with graphical_model:\n",
    "                        exec(f\"weight_{weight_idx} = pm.Normal('weight_{weight_idx}', \\\n",
    "                                mu={combined_string}, sigma=public_grads_stdev)\")\n",
    "                        exec(f\"weight_observed_{weight_idx} = pm.Normal('weight_observed_{weight_idx}', \\\n",
    "                                 mu=weight_{weight_idx}, sigma=gaussian_stdev, observed=dp_grad)\")\n",
    "                weight_idx += 1\n",
    "\n",
    "    map_estimates = pm.find_MAP(model=graphical_model, progressbar=False)\n",
    "    for key, value in map_estimates.items():\n",
    "        layer_num, idx = grad_name_mapping[key]\n",
    "        map_grads[layer_num][idx] = value\n",
    "\n",
    "    return map_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_public_grads(public_x, public_y, loss_fn, model):\n",
    "    public_grads = []\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    for x, y in zip(public_x, public_y):\n",
    "#     for x, y in tqdm(zip(public_x, public_y), total=public_x.shape[0], desc='Public Dataset Iter'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(y, model(x))\n",
    "            grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "        if not public_grads:\n",
    "            public_grads = [[] for _ in grad]\n",
    "        for i, t in enumerate(grad):\n",
    "            public_grads[i].append(t.numpy())\n",
    "    public_grads = [np.asarray(l) for l in public_grads]\n",
    "    return public_grads\n",
    "\n",
    "def get_public_grads_mean_var(public_x, public_y, loss_fn, model):\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    # https://math.stackexchange.com/questions/20593/calculate-variance-from-a-stream-of-sample-values\n",
    "    mean_k = None\n",
    "    v_k = None\n",
    "    k = 0\n",
    "    for x, y in zip(public_x, public_y):\n",
    "        k += 1\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(y, model(x))\n",
    "            grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "        numpy_grad = [t.numpy() for t in grad]\n",
    "        if k == 1:\n",
    "            mean_k = numpy_grad\n",
    "            v_k = [np.zeros(t.shape) for t in numpy_grad]\n",
    "        else:\n",
    "            prev_mean_k = mean_k\n",
    "            mean_k = [mean_k[i] + (t - mean_k[i]) / k for i, t in enumerate(numpy_grad)]\n",
    "            v_k = [v_k[i] +  np.multiply(t - prev_mean_k[i], \n",
    "                                         t - mean_k[i]) \n",
    "                   for i, t in enumerate(numpy_grad)]\n",
    "    unbiased_variance = [t / (k - 1) for t in v_k]\n",
    "    return mean_k, unbiased_variance\n",
    "\n",
    "def evaluate_model(model, loss_fn, x, y):\n",
    "    pred = model(x)\n",
    "    loss = np.mean(loss_fn(y, pred).numpy())\n",
    "    acc = np.mean(tf.keras.metrics.categorical_accuracy(y, pred).numpy())\n",
    "    return (loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae8fe241b364532a77e7adc33360b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=300, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 25', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 26', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 27', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 28', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 29', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 30', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 31', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 32', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 33', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 34', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 35', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 36', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 37', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 38', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 39', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 40', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 41', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 42', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 43', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 44', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 45', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 46', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 47', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 48', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 49', max=300, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.1135633, 0.355)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "pretrained_model = cnn_model()\n",
    "pretrained_model.compile(optimizer='adam',\n",
    "                       loss=loss_fn, metrics=['accuracy'])\n",
    "baseline_history = pretrained_model.fit(public_data, public_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[TQDMNotebookCallback(), EarlyStopping(monitor='acc', patience=5)])\n",
    "evaluate_model(pretrained_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4iV03VqG1Bo"
   },
   "outputs": [],
   "source": [
    "dpsgd_model_pretrained = cnn_model()\n",
    "dpsgd_model_pretrained.set_weights(pretrained_model.get_weights())\n",
    "dpsgd_optimizer_pretrained = DPAdamGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "dpsgd_model_pretrained.compile(optimizer=dpsgd_optimizer_pretrained, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "bayesian_model_pretrained = cnn_model()\n",
    "bayesian_model_pretrained.set_weights(pretrained_model.get_weights())\n",
    "bayesian_optimizer_pretrained = DPAdamGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "bayesian_model_pretrained.compile(optimizer=bayesian_optimizer_pretrained, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "bayesian_network_model_pretrained = cnn_model()\n",
    "bayesian_network_model_pretrained.set_weights(pretrained_model.get_weights())\n",
    "bayesian_network_optimizer_pretrained = DPAdamGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "bayesian_network_model_pretrained.compile(\n",
    "    optimizer=bayesian_network_optimizer_pretrained, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b7ecae216b4f6d93649ca1cad3c9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4daf37edbe4e9aa7e3c1ae2c267b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=597, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:From /home/qinghao/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py:562: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:From /home/qinghao/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c510b7ebc05e4c5fbd8a11e929c5e9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Graph Layer', max=4, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Graph Weight', max=3136, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Graph Weight', max=4, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcbf1607d7c4811a3a690c972416c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Graph Weight', max=40, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "dpsgd_loss_pretrained_batches = []\n",
    "dpsgd_acc_pretrained_batches = []\n",
    "\n",
    "bayesian_loss_pretrained_batches = []\n",
    "bayesian_acc_pretrained_batches = []\n",
    "\n",
    "bayesian_network_loss_pretrained_batches = []\n",
    "bayesian_network_acc_pretrained_batches = []\n",
    "\n",
    "# Used for picking a random minibatch\n",
    "idx_array = np.arange(private_data.shape[0])\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step in tqdm(range(num_batches), desc='Batch', leave=False):\n",
    "        \n",
    "        # Pick a random minibatch\n",
    "        random_idx = np.random.choice(idx_array, batch_size)\n",
    "        x_batch_train = private_data[random_idx]\n",
    "        y_batch_train = private_labels[random_idx]\n",
    "        \n",
    "        ### DPSGD pretrained\n",
    "    \n",
    "        # Evaluate DPSGD model\n",
    "        loss, acc = evaluate_model(dpsgd_model_pretrained, loss_fn, test_data, test_labels)\n",
    "#         print('DPSGD Loss: %.4f | Acc: %.4f' % (loss, acc))\n",
    "        dpsgd_loss_pretrained_batches.append(loss)\n",
    "        dpsgd_acc_pretrained_batches.append(acc)\n",
    "    \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = dpsgd_model_pretrained(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = dpsgd_optimizer_pretrained.compute_gradients(\n",
    "                loss, dpsgd_model_pretrained.trainable_weights, gradient_tape=tape)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        dpsgd_optimizer_pretrained.apply_gradients(grads)\n",
    "        \n",
    "        ### Our simple Bayesian DPSGD pretrained\n",
    "    \n",
    "        # Evaluate custom model\n",
    "        loss, acc = evaluate_model(bayesian_model_pretrained, loss_fn, test_data, test_labels)\n",
    "#         print('Custom Loss: %.4f | Acc: %.4f' % (loss, acc))\n",
    "        bayesian_loss_pretrained_batches.append(loss)\n",
    "        bayesian_acc_pretrained_batches.append(acc)\n",
    "\n",
    "        means, variances = get_public_grads_mean_var(public_data, public_labels, loss_fn, bayesian_model_pretrained)\n",
    "        variances = [layer * public_var_multiplier for layer in variances]\n",
    "        \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = bayesian_model_pretrained(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = bayesian_optimizer_pretrained.compute_gradients(\n",
    "                    loss, bayesian_model_pretrained.trainable_weights, gradient_tape=tape)\n",
    "\n",
    "        del tape\n",
    "        \n",
    "        # X = N(means, variances)\n",
    "        # Y = X + N(0, gaussian_noise_var)\n",
    "        # MLE of X is ((variances * Y) + (gaussian_noise_var * means)) / (variances + gaussian_noise_var)\n",
    "        # https://www.wolframalpha.com/input/?i=differentiate+-log%28%CF%83%29+-+1%2F2+log%282+%CF%80%29+-+1%2F2+%28%28x+-+%CE%BC%29%2F%CF%83%29%5E2+-log%28%CE%A3%29+-+1%2F2+log%282+%CF%80%29+-+1%2F2+%28%28y+-+x%29%2F%CE%A3%29%5E2+wrt+x\n",
    "        # https://www.wolframalpha.com/input/?i=solve+%28y+-+x%29%2F%CE%A3%5E2+-+%28x+-+%CE%BC%29%2F%CF%83%5E2+for+x\n",
    "        Ys = [grad[0] for grad in grads]\n",
    "        Xs = [((Y * variances[i]) + (means[i] * gaussian_noise_var)) / (variances[i] + gaussian_noise_var)\n",
    "              for i, Y in enumerate(Ys)]\n",
    "        adjusted_grads = list(zip(Xs, bayesian_model_pretrained.trainable_weights))\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        bayesian_optimizer_pretrained.apply_gradients(adjusted_grads)\n",
    "        \n",
    "        \n",
    "        ### Our Bayesian graph DPSGD pretrained\n",
    "    \n",
    "        # Evaluate custom model\n",
    "        loss, acc = evaluate_model(bayesian_network_model_pretrained, loss_fn, test_data, test_labels)\n",
    "#         print('Custom Loss: %.4f | Acc: %.4f' % (loss, acc))\n",
    "        bayesian_network_loss_pretrained_batches.append(loss)\n",
    "        bayesian_network_acc_pretrained_batches.append(acc)\n",
    "        \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = bayesian_network_model_pretrained(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = bayesian_network_optimizer_pretrained.compute_gradients(\n",
    "                                                            loss,\n",
    "                                                            bayesian_network_model_pretrained.trainable_weights,\n",
    "                                                            gradient_tape=tape)\n",
    "\n",
    "        del tape\n",
    "        \n",
    "        public_grads = get_public_grads(public_data, public_labels, loss_fn, bayesian_model_pretrained)\n",
    "        dp_grads = [g[0].numpy() for g in grads]\n",
    "        map_grads = construct_graphical_model_and_get_map(public_grads, dp_grads)\n",
    "        \n",
    "        bayesian_network_optimizer_pretrained.apply_gradients(\n",
    "            zip(map_grads, bayesian_network_model_pretrained.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(bayesian_network_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dpsgd_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dpsgd_acc  simple_bayesian_acc  bayesian_network_acc\n",
      "0      0.355                0.355                 0.355\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.DataFrame({\n",
    "                        'dpsgd_acc': dpsgd_acc_pretrained_batches,\n",
    "                        'simple_bayesian_acc': bayesian_acc_pretrained_batches,\n",
    "                        'bayesian_network_acc': bayesian_network_acc_pretrained_batches,\n",
    "                       })\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(data=metrics[:200])\n",
    "ax.set(xlabel='Minibatch', ylabel='Loss/Acc', \n",
    "       title='MNIST Bayesian DPSGD (Norm Clip={}, Public Size={})'.format(l2_norm_clip, public_data.shape[0]))\n",
    "plt.savefig('mnist_bayesian_network-pretrained_variance{}_dpsgd-norm{}.png'\n",
    "            .format(public_var_multiplier, l2_norm_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_Privacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
