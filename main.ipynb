{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef56gCUqrdVn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "assert tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E14tL1vUuTRV"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXNp_25y7JP2"
   },
   "source": [
    "DP-SGD has three privacy-specific hyperparameters and one existing hyperamater that you must tune:\n",
    "\n",
    "1. `l2_norm_clip` (float) - The maximum Euclidean (L2) norm of each gradient that is applied to update model parameters. This hyperparameter is used to bound the optimizer's sensitivity to individual training points. \n",
    "2. `noise_multiplier` (float) - The amount of noise sampled and added to gradients during training. Generally, more noise results in better privacy (often, but not necessarily, at the expense of lower utility).\n",
    "3.   `microbatches` (int) - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVw_r2Mq7ntd"
   },
   "outputs": [],
   "source": [
    "l2_norm_clip = 0.02\n",
    "noise_multiplier = 1\n",
    "num_microbatches = 1\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "  raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentile at which to clip norm, based on public data gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_percentile = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1ML23FlueTr"
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "assert train_data.min() == 0.\n",
    "assert train_data.max() == 1.\n",
    "assert test_data.min() == 0.\n",
    "assert test_data.max() == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size refers to private data size\n",
    "public_data, private_data, public_labels, private_labels = \\\n",
    "    train_test_split(train_data, train_labels, test_size=0.98)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((private_data, private_labels))\n",
    "# Data is already shuffled\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "num_batches = private_data.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3)\n",
      "(1000, 10)\n",
      "(49000, 32, 32, 3)\n",
      "(49000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(public_data.shape)\n",
    "print(public_labels.shape)\n",
    "print(private_data.shape)\n",
    "print(private_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws8-nVuVDgtJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 1.02% and noise_multiplier = 1 iterated over 1960 steps satisfies differential privacy with eps = 3.38 and delta = 1e-05.\n",
      "The optimal RDP order is 7.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.382117679728355, 7.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    n=private_labels.shape[0], batch_size=batch_size, noise_multiplier=noise_multiplier, epochs=epochs, delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqBvjCf5-ZXy"
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(train_labels.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPAdamGaussianOptimizer\n",
    "\n",
    "optimizer = DPAdamGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(arr):\n",
    "    return np.sqrt(np.sum(np.square(arr)))\n",
    "\n",
    "def get_public_grads(public_x, public_y, loss_fn, model):\n",
    "    public_grads = []\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    for x, y in zip(public_x, public_y):\n",
    "#     for x, y in tqdm(zip(public_x, public_y), total=public_x.shape[0], desc='Public Dataset Iter'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(y, model(x))\n",
    "            grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "        grad_norms = [l2_norm(t.numpy()) for t in grad]\n",
    "        public_grads.append(grad_norms)\n",
    "    # Index is (Layer, Example)\n",
    "    return np.swapaxes(np.asarray(public_grads), 0, 1)\n",
    "\n",
    "def get_grads_percentile(public_grads, percentile):\n",
    "    layer_percentiles = []\n",
    "    for layer in public_grads:\n",
    "        layer_percentile = np.percentile(np.asarray(layer), norm_percentile, axis=0)\n",
    "        layer_percentiles.append(layer_percentile)\n",
    "    return layer_percentiles\n",
    "\n",
    "def evaluate_model(model, loss_fn, x, y):\n",
    "    pred = model(x)\n",
    "    loss = np.mean(loss_fn(y, pred).numpy())\n",
    "    acc = np.mean(tf.keras.metrics.categorical_accuracy(y, pred).numpy())\n",
    "    return (loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4iV03VqG1Bo"
   },
   "outputs": [],
   "source": [
    "clipped_model = cnn_model()\n",
    "clipped_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2dec4a5f4c4b71869d5e4aca16386b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 2.3025, Acc: 0.1053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1571e591f5cf444590e26b86518d36d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=98, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:From /home/qinghao/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/array_grad.py:562: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:From /home/qinghao/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "clipped_loss_epochs = []\n",
    "clipped_acc_epochs = []\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, acc = evaluate_model(clipped_model, loss_fn, test_data, test_labels)\n",
    "    print(\"Epoch %d - Loss: %.4f, Acc: %.4f\" % (epoch, loss, acc))\n",
    "    clipped_loss_epochs.append(loss)\n",
    "    clipped_acc_epochs.append(acc)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(tqdm(train_dataset, total=num_batches, desc='Batch')):\n",
    "\n",
    "        public_grads = get_public_grads(public_data, public_labels, loss_fn, clipped_model)\n",
    "        grad_percentiles_by_layer = get_grads_percentile(public_grads, norm_percentile)\n",
    "\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = clipped_model(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = optimizer.compute_gradients(loss, clipped_model.trainable_weights, gradient_tape=tape, \n",
    "                                                gradient_clips=grad_percentiles_by_layer)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2185864, 0.2493)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(clipped_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpsgd_model = cnn_model()\n",
    "dpsgd_optimizer = DPAdamGaussianOptimizer(\n",
    "                        l2_norm_clip=1e20,\n",
    "                        noise_multiplier=0,\n",
    "                        num_microbatches=num_microbatches)\n",
    "dpsgd_model.compile(optimizer=dpsgd_optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over epochs.\n",
    "dpsgd_loss_epochs = []\n",
    "dpsgd_acc_epochs = []\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, acc = evaluate_model(dpsgd_model, loss_fn, test_data, test_labels)\n",
    "    print(\"Epoch %d - Loss: %.4f, Acc: %.4f\" % (epoch, loss, acc))\n",
    "    dpsgd_loss_epochs.append(loss)\n",
    "    dpsgd_acc_epochs.append(acc)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(tqdm(train_dataset, total=num_batches, desc='Batch')):\n",
    "\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = dpsgd_model(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = optimizer.compute_gradients(loss, dpsgd_model.trainable_weights, gradient_tape=tape)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1961298, 0.2562)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(dpsgd_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = cnn_model()\n",
    "baseline_model.compile(optimizer='adam',\n",
    "                       loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.fit(private_data, private_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7536906, 0.7084)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(baseline_model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    clipped_acc  clipped_loss  dpsgd_acc  dpsgd_loss\n",
      "0        0.1053      2.302472     0.1014    2.302490\n",
      "1        0.1080      2.302099     0.1199    2.295525\n",
      "2        0.1163      2.301540     0.1644    2.279847\n",
      "3        0.1420      2.300859     0.1724    2.265790\n",
      "4        0.1080      2.299913     0.2059    2.251234\n",
      "5        0.1072      2.298108     0.2208    2.238546\n",
      "6        0.1167      2.295257     0.2199    2.233988\n",
      "7        0.1046      2.292071     0.2461    2.223210\n",
      "8        0.1344      2.288850     0.2411    2.221355\n",
      "9        0.1439      2.283451     0.2384    2.217652\n",
      "10       0.1479      2.280169     0.2441    2.216614\n",
      "11       0.1624      2.275744     0.2459    2.212863\n",
      "12       0.1988      2.270431     0.2431    2.212710\n",
      "13       0.2153      2.262354     0.2375    2.213625\n",
      "14       0.2344      2.251984     0.2385    2.209715\n",
      "15       0.2335      2.243893     0.2471    2.206144\n",
      "16       0.2439      2.235283     0.2562    2.197630\n",
      "17       0.2476      2.231877     0.2513    2.197394\n",
      "18       0.2508      2.226001     0.2469    2.202847\n",
      "19       0.2512      2.222150     0.2506    2.198633\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = pd.DataFrame({'clipped_loss': clipped_loss_epochs,\n",
    "                        'dpsgd_loss': dpsgd_loss_epochs,\n",
    "                        'clipped_acc': clipped_acc_epochs,\n",
    "                        'dpsgd_acc': dpsgd_acc_epochs})\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.lineplot(data=metrics)\n",
    "ax.set(xlabel='Epoch', ylabel='Loss/Acc', title='CIFAR10')\n",
    "plt.savefig('cifar10-{}.png'.format(norm_percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_Privacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
