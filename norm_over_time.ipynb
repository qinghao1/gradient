{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef56gCUqrdVn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import random; random.seed(42)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "assert tf.executing_eagerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E14tL1vUuTRV"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXNp_25y7JP2"
   },
   "source": [
    "DP-SGD has three privacy-specific hyperparameters and one existing hyperamater that you must tune:\n",
    "\n",
    "1. `l2_norm_clip` (float) - The maximum Euclidean (L2) norm of each gradient that is applied to update model parameters. This hyperparameter is used to bound the optimizer's sensitivity to individual training points. \n",
    "2. `noise_multiplier` (float) - The amount of noise sampled and added to gradients during training. Generally, more noise results in better privacy (often, but not necessarily, at the expense of lower utility).\n",
    "3.   `microbatches` (int) - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVw_r2Mq7ntd"
   },
   "outputs": [],
   "source": [
    "l2_norm_clip = 0.5\n",
    "noise_multiplier = 1\n",
    "num_microbatches = batch_size\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "  raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1ML23FlueTr"
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "train_data = np.expand_dims(train_data, len(train_data.shape))\n",
    "test_data = np.expand_dims(test_data, len(test_data.shape))\n",
    "\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "assert train_data.min() == 0.\n",
    "assert train_data.max() == 1.\n",
    "assert test_data.min() == 0.\n",
    "assert test_data.max() == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size refers to private data size\n",
    "public_data, private_data, public_labels, private_labels = \\\n",
    "    train_test_split(train_data, train_labels, test_size=239/240)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((private_data, private_labels))\n",
    "# Data is already shuffled\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "num_batches = private_data.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 28, 28, 1)\n",
      "(250, 10)\n",
      "(59750, 28, 28, 1)\n",
      "(59750, 10)\n"
     ]
    }
   ],
   "source": [
    "print(public_data.shape)\n",
    "print(public_labels.shape)\n",
    "print(private_data.shape)\n",
    "print(private_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws8-nVuVDgtJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.418% and noise_multiplier = 1 iterated over 239 steps satisfies differential privacy with eps = 1.32 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.3214478128710707, 10.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    n=private_labels.shape[0], batch_size=batch_size, noise_multiplier=noise_multiplier, epochs=epochs, delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqBvjCf5-ZXy"
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=train_data.shape[1:]))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.load_weights('mnist_initial_weights.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(arr):\n",
    "    return np.sqrt(np.sum(np.square(arr)))\n",
    "\n",
    "def get_public_grads_layer_norms(public_x, public_y, loss_fn, model):\n",
    "    public_grads = []\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    for x, y in zip(public_x, public_y):\n",
    "#     for x, y in tqdm(zip(public_x, public_y), total=public_x.shape[0], desc='Public Dataset Iter'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(y, model(x))\n",
    "            grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "        grad_norms = [l2_norm(t.numpy()) for t in grad]\n",
    "        public_grads.append(grad_norms)\n",
    "    # Index is (Layer, Example)\n",
    "    return np.swapaxes(np.asarray(public_grads), 0, 1)\n",
    "\n",
    "def get_layer_norms_percentile(layer_norms, percentile):\n",
    "    layer_percentiles = []\n",
    "    for layer in layer_norms:\n",
    "        layer_percentile = np.percentile(np.asarray(layer), norm_percentile, axis=0)\n",
    "        layer_percentiles.append(layer_percentile)\n",
    "    return layer_percentiles\n",
    "\n",
    "def get_total_norm(x, y, loss_fn, model):\n",
    "    if x.shape[0] != 1:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(y, model(x))\n",
    "        grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "    return np.sqrt(sum([np.sum(np.square(t.numpy())) for t in grad]))\n",
    "\n",
    "def get_public_total_norms(public_x, public_y, loss_fn, model):\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    return [get_total_norm(x, y, loss_fn, model) for x, y in zip(public_x, public_y)]\n",
    "\n",
    "def get_public_total_norm_percentile(public_total_norms, norm_percentile):\n",
    "    return np.percentile(public_total_norms, norm_percentile)\n",
    "\n",
    "def get_public_grads_weights(public_x, public_y, loss_fn, model):\n",
    "    public_grads = []\n",
    "    # x needs to have extra dimension for number of examples,\n",
    "    # even if it's 1 for our case\n",
    "    public_x = np.expand_dims(public_x, axis=1)\n",
    "    for x, y in zip(public_x, public_y):\n",
    "#     for x, y in tqdm(zip(public_x, public_y), total=public_x.shape[0], desc='Public Dataset Iter'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(y, model(x))\n",
    "            grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "        abs_weights = [np.abs(t.numpy()) for t in grad]\n",
    "        public_grads.append(abs_weights)\n",
    "    # Index is (Layer, Example)\n",
    "    return np.swapaxes(np.asarray(public_grads), 0, 1)\n",
    "\n",
    "def get_weights_percentile(public_weights, percentile):\n",
    "    layer_percentiles = []\n",
    "    for layer in public_weights:\n",
    "        layer_percentile = np.percentile(np.stack(layer), norm_percentile, axis=0)\n",
    "        layer_percentiles.append(layer_percentile)\n",
    "    return layer_percentiles\n",
    "\n",
    "def evaluate_model(model, loss_fn, x, y):\n",
    "    pred = model(x)\n",
    "    loss = np.mean(loss_fn(y, pred).numpy())\n",
    "    acc = np.mean(tf.keras.metrics.categorical_accuracy(y, pred).numpy())\n",
    "    return (loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "optimizer = DPAdamGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7736f2701c384c80b5d354425b822602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 2.3028, Acc: 0.0571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dab937a1e147cc8f155c7739165e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=239, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:From /home/qinghao/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/array_grad.py:562: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:From /home/qinghao/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ba5b6bed301b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# the gradients of the trainable variables with respect to the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             grads = optimizer.compute_gradients(loss, model.trainable_weights,\n\u001b[0;32m---> 36\u001b[0;31m                                                               gradient_tape=tape)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gradient/privacy/tensorflow_privacy/privacy/optimizers/dp_optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss, gradient_tape, layer_norm_clips, weight_val_clips, new_l2_norm_clip)\u001b[0m\n\u001b[1;32m    131\u001b[0m           sample_state = process_microbatch(idx, sample_state,\n\u001b[1;32m    132\u001b[0m                                             \u001b[0mlayer_norm_clips\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                             weight_val_clips)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         grad_sums, self._global_state = (\n",
      "\u001b[0;32m~/gradient/privacy/tensorflow_privacy/privacy/optimizers/dp_optimizer.py\u001b[0m in \u001b[0;36mprocess_microbatch\u001b[0;34m(i, sample_state, layer_norm_clips, weight_val_clips)\u001b[0m\n\u001b[1;32m    107\u001b[0m           microbatch_loss = tf.reduce_mean(\n\u001b[1;32m    108\u001b[0m               input_tensor=tf.gather(microbatches_losses, [i]))\n\u001b[0;32m--> 109\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrobatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlayer_norm_clips\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qinghao/lib/python3.5/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qinghao/lib/python3.5/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/qinghao/lib/python3.5/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qinghao/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "clipped_loss_epochs = []\n",
    "clipped_acc_epochs = []\n",
    "norms_batches = []\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, acc = evaluate_model(model, loss_fn, private_data, private_labels)\n",
    "    print(\"Epoch %d - Loss: %.4f, Acc: %.4f\" % (epoch, loss, acc))\n",
    "    clipped_loss_epochs.append(loss)\n",
    "    clipped_acc_epochs.append(acc)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(tqdm(train_dataset, total=num_batches, desc='Batch')):\n",
    "\n",
    "        public_total_norms = get_public_total_norms(public_data, public_labels, loss_fn, model)\n",
    "        norms_batches.append(np.median(public_total_norms))\n",
    "        \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss = lambda: loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = optimizer.compute_gradients(loss, model.trainable_weights,\n",
    "                                                              gradient_tape=tape)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, loss_fn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Public Norm\n",
      "0      0.490757\n",
      "1      0.498973\n",
      "2      0.504993\n",
      "3      0.512482\n",
      "4      0.520691\n",
      "5      0.529405\n",
      "6      0.544920\n",
      "7      0.564867\n",
      "8      0.585153\n",
      "9      0.611095\n",
      "10     0.638045\n",
      "11     0.670863\n",
      "12     0.701900\n",
      "13     0.749463\n",
      "14     0.797538\n",
      "15     0.853511\n",
      "16     0.905675\n",
      "17     0.958076\n",
      "18     1.017910\n",
      "19     1.091786\n",
      "20     1.151783\n",
      "21     1.244028\n",
      "22     1.337149\n",
      "23     1.432102\n",
      "24     1.557000\n",
      "25     1.702052\n",
      "26     1.844732\n",
      "27     1.986834\n",
      "28     2.148806\n",
      "29     2.290630\n",
      "30     2.456715\n",
      "31     2.655486\n",
      "32     2.850729\n",
      "33     3.060460\n",
      "34     3.270918\n",
      "35     3.478860\n",
      "36     3.645034\n",
      "37     3.874516\n",
      "38     4.135587\n",
      "39     4.343955\n",
      "40     4.508960\n",
      "41     4.663568\n",
      "42     4.869495\n",
      "43     5.026430\n",
      "44     5.169460\n",
      "45     5.324249\n",
      "46     5.397785\n",
      "47     5.481486\n",
      "48     5.542372\n",
      "49     5.692319\n",
      "50     5.616445\n",
      "51     5.685456\n",
      "52     5.698852\n",
      "53     5.552296\n",
      "54     5.399696\n",
      "55     5.442460\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.DataFrame({\n",
    "#                         'clipped_loss': clipped_loss_epochs,\n",
    "#                         'clipped_acc': clipped_acc_epochs,\n",
    "                        'Public Norm': norms_batches,\n",
    "                       })\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(data=metrics)\n",
    "ax.set(xlabel='Batch', ylabel='Public Norm', title='MNIST')\n",
    "plt.savefig('mnist_norm_over_time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_Privacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
